# Task Process Mapping

Once the decomposition phase is complete, tasks are mapped to processes with the goal for all tasks to complete in the shortest amount of time. To reduce the cost, which is the measure of time to complete a task, the incurred overhead during the parallel task execution must be reduced. The overhead can either be caused by the time spent during the interaction between processes or during the idle time for each task. Tasks go through several stages during their life cycle, including an idle time during which tasks may be waiting for some data to be generated by other tasks.

This can be caused by an uneven task load distribution, which may cause unfinished tasks to wait for other tasks as dictated by the dependency graph. An effective task–process mapping should have two major goals—reducing the time that processes spend during the interaction and reducing the amount of idle time. These two objectives are often mutually exclusive. For instance, to minimize interactions between tasks, you can map tasks that need to interact with each other to the same process. However, this will result in a skewed load balancing between processes. This will also lead to a situation where processes with a lighter load can be idle while those with a heavier load are attempting to finish their work. On the other hand, to properly balance the load between processes, it may be required to assign tasks that interact heavily with other processes. This is partly the reason why building a good process–task mapping is not a simple task.

There are two major classifications of mapping–static and dynamic.

## Static

Static mapping processes distribute the tasks among the available processes before the execution of the program. For those tasks that are generated through the static generation technique, both static and dynamic mapping can be used. However, several factors should be taken into account, including the size of the task and associated data. The characteristics of the intertask interactions are also critical to help determine good mapping. Keep in mind that, even if you know the task sizes, the problem of obtaining an optimal mapping is not an easy task. Programs using static mapping are typically easier to design.

## Dynamic

Unlike static mapping, dynamic mapping approaches distribute the tasks among multiple processes during the execution of the program. If tasks resulted from the dynamic generation, they need to be mapped dynamically as well. If the task size is not provided, a static mapping may lead to some load imbalance. If the data that are tied to the tasks are large, dynamic mapping may require the move of these data to other processes. The dynamic mapping may not be a suitable approach if the cost of the data movement between tasks is too high. In this case, static mapping may be more suitable. In addition, programs using the dynamic mapping approach are typically more complex.

## Array Distribution Schemes

In the case of data partitioning, the tasks are connected to portions of data by the owner-computers rule. This means that mapping the relevant data to processes is similar to mapping subprograms to processes. One of the simplest methods for distributing an array and assigning uniform contiguous sections of the array to processes is known as block distribution. In this case, an n-dimensional array can be distributed between multiple processes, where each process can work on a specific block of the array. This technique is best used when computing an element may require other nearby sections of the array.
